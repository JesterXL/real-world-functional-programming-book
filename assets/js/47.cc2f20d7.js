(window.webpackJsonp=window.webpackJsonp||[]).push([[47],{247:function(t,s,a){"use strict";a.r(s);var n=a(0),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"composing-functions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#composing-functions"}},[t._v("#")]),t._v(" Composing Functions")]),t._v(" "),a("p",[t._v("// [jwarden 3.10.2019] TODO/FIXME: We need to drive the partial application usage home. We're also missing using the pipeline operator which makes way more sense. We should probably just expand this section to show before/after of partial, and then create a new section for pipeline since I have a pretty good example of that here: https://gist.github.com/JesterXL/174a83a21fdff671bc5a7a8c954c6949 We should probably also separate flow, promises, and the pipeline operator into their own sections. The overview here is good, but each has different users. Finally, as much as I loathe RxJS, we should probably give it some love to show it's power in mixing async and sync.")]),t._v(" "),a("p",[t._v("Composing functions is when you combine a bunch of functions together to form a new function. When you build applications using Functional Programming, you'll be building new functions from existing functions. Flow in Lodash, Compose in Ramda, Folktale, and Sanctuary, allow you to pipe functions together in JavaScript. We briefly showed an example of this in the "),a("router-link",{attrs:{to:"/part5_old/tacit_programming.html"}},[t._v("Tacit Programming")]),t._v(" section using "),a("code",[t._v("flow")]),t._v(". Python and Lua make this a lot easier since both synchronous things like adding numbers and asynchronous things like loading data from websites work the exact the same way if you use the basics of the language.")],1),t._v(" "),a("p",[t._v("JavaScript, however, handles asynchronous completely differently through "),a("code",[t._v("Promises")]),t._v(", Python optionally through their various concurrency options, and Lua through coroutines. We'll cover both below so you'll be deadly no matter which language you choose to wield. Also, RxJS and other libraries have been created to allow composition in JavaScript without caring if it is asynchronous or not.")]),t._v(" "),a("h2",{attrs:{id:"prior-art-chaining"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#prior-art-chaining"}},[t._v("#")]),t._v(" Prior Art: Chaining")]),t._v(" "),a("p",[t._v('A lot of languages and libraries already do some form of composition where you\'ll "dot chain" functions together to string together the output of one into the arguments of another.')]),t._v(" "),a("p",[t._v("String and Array in plain JavaScript:")]),t._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Jesse,Brandy'")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("split")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("','")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("name")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token template-string"}},[a("span",{pre:!0,attrs:{class:"token template-punctuation string"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token interpolation-punctuation punctuation"}},[t._v("${")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token interpolation-punctuation punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v(" is crunk on vacay, urrrkaaayy!")]),a("span",{pre:!0,attrs:{class:"token template-punctuation string"}},[t._v("`")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sort")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("join")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\n'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toUpperCase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// BRANDY IS CRUNK ON VACAY, URRRKAAAYY!")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// JESSE IS CRUNK ON VACAY, URRRKAAAYY!")]),t._v("\n")])])]),a("p",[t._v("Chaining selectors in "),a("a",{attrs:{href:"https://jquery.com/",target:"_blank",rel:"noopener noreferrer"}},[t._v("JQuery"),a("OutboundLink")],1),t._v(":")]),t._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[t._v("$")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("document"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("ready")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("$")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'#dvContent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("addClass")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dummy'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("css")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'color'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'red'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("fadeIn")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'slow'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("    \n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("And straddling both the sync and async worlds of JavaScript using RxJS (the "),a("code",[t._v("listAWSFunctions")]),t._v(" makes a REST call that may take awhile):")]),t._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" fromPromise"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("require")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rx'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("getLambdaFunctions")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("functions")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("fromPromise")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("listAWSFunctions")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("functions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("pluck")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Functions'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("selectMany")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("lambda")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Runtime'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lambda"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'nodejs'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("containsBasicRole"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toArray")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"sync-with-flow"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sync-with-flow"}},[t._v("#")]),t._v(" Sync With Flow")]),t._v(" "),a("p",[t._v("To get a list of human names from our party in JSON will be a series of pure parsing functions. We'll compose them together keeping them as point-free as possible.")]),t._v(" "),a("p",[t._v("Our party in JSON:")]),t._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" peopleString "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token template-string"}},[a("span",{pre:!0,attrs:{class:"token template-punctuation string"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('[\n  ["jesse warden", "swasbuckler", 18, 21, "human"],\n  ["brandy fortune", "cleric", 11, 11, "human"],\n  ["albus dumbledog", "war dog", 7, 9, "dawg"]\n]')]),a("span",{pre:!0,attrs:{class:"token template-punctuation string"}},[t._v("`")])]),t._v("\n")])])]),a("h2",{attrs:{id:"parsing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parsing"}},[t._v("#")]),t._v(" Parsing")]),t._v(" "),a("p",[t._v("Let's create our function and continue to add to it so we can see the process of how composition starts small and simple, yet can be augmented over time.")]),t._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" flow "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lodash/fp'")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" showHumans "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("flow")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("JSON")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nconsole"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("showHumans")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("peopleString"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// [ [ 'jesse warden', 'swasbuckler', 18, 21, 'human' ],")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   [ 'brandy fortune', 'cleric', 11, 11, 'human' ],")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   [ 'albus dumbledog', 'war dog', 7, 9, 'dawg' ] ]")]),t._v("\n")])])]),a("p",[t._v("The "),a("code",[t._v("JSON.parse")]),t._v(" function takes 1 parameter, a String, and will output the parsed JSON Object. It's not pure because it'll throw if the String fails to parse, but we'll handle that scenario in "),a("router-link",{attrs:{to:"/part5_old/part6/"}},[t._v("Part 6: Algebraic Data Types")]),t._v(".")],1),t._v(" "),a("h2",{attrs:{id:"list-to-people"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#list-to-people"}},[t._v("#")]),t._v(" List to People")]),t._v(" "),a("p",[t._v("Our party members have their attributes flattened into an Array. Let's convert them to proper people Objects. e'll give the "),a("code",[t._v("map")]),t._v(" our list of party members, and he'll destructure the Array into properties, then return them in an Object with the properties having the same name:")]),t._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" listToPeople "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" clazz"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hitPoints"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" maxHitPoints"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" type"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" clazz"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hitPoints"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" maxHitPoints"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" type "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Plugged into our flow, she'll get whatever "),a("code",[t._v("JSON.parse")]),t._v(" spits out:")]),t._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" showHumans "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("flow")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("JSON")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    listToPeople\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nconsole"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("showHumans")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("peopleString"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// [ { name: 'jesse warden',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     clazz: 'swasbuckler',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     hitPoints: 18,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     maxHitPoints: 21,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     type: 'human' },")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   { name: 'brandy fortune',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     clazz: 'cleric',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     hitPoints: 11,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     maxHitPoints: 11,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     type: 'human' },")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   { name: 'albus dumbledog',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     clazz: 'war dog',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     hitPoints: 7,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     maxHitPoints: 9,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     type: 'dawg' } ]")]),t._v("\n")])])]),a("h2",{attrs:{id:"filter-humans"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#filter-humans"}},[t._v("#")]),t._v(" Filter Humans")]),t._v(" "),a("p",[t._v("Like we've shown in the previous section, if any of the person's type is a human, we keep those in the newly returned Array. This means no Albus the dog in the filtered "),a("code",[t._v("party")]),t._v(" Array.")]),t._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" filterHumans "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("person")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getOr")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'unknown'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'type'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" person"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'human'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Plugging her in:")]),t._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" showHumans "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("flow")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("JSON")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    listToPeople"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    filterHumans\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nconsole"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("showHumans")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("peopleString"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// [ { name: 'jesse warden',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     clazz: 'swasbuckler',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     hitPoints: 18,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     maxHitPoints: 21,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     type: 'human' },")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   { name: 'brandy fortune',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     clazz: 'cleric',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     hitPoints: 11,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     maxHitPoints: 11,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     type: 'human' } ]")]),t._v("\n")])])]),a("h2",{attrs:{id:"fix-name-casing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#fix-name-casing"}},[t._v("#")]),t._v(" Fix Name Casing")]),t._v(" "),a("p",[t._v("We can correct the casing of the names using Lodash' "),a("code",[t._v("startCase")]),t._v(" method. It'll change 'jesse warden' to 'Jesse Warden'. We covered "),a("code",[t._v("set")]),t._v(" in "),a("router-link",{attrs:{to:"/part5_old/part3/set.html"}},[t._v("Part 3: Set")]),t._v(", the function used to clone an Object and update a piece of data on the clone. We'll use both below to correct the casing of all the names on the human party members:")],1),t._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" formatNames "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'name'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("startCase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'name'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Popping her in results in both names fixed:")]),t._v(" "),a("div",{staticClass:"language-javascript extra-class"},[a("pre",{pre:!0,attrs:{class:"language-javascript"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" showHumans "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("flow")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("JSON")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    listToPeople"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    filterHumans"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    formatNames\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nconsole"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("showHumans")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("peopleString"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// [ { name: 'Jesse Warden',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     clazz: 'swasbuckler',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     hitPoints: 18,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     maxHitPoints: 21,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     type: 'human' },")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//   { name: 'Brandy Fortune',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     clazz: 'cleric',")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     hitPoints: 11,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     maxHitPoints: 11,")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//     type: 'human' } ]")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);